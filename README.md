# GPT-2 Text Generator

This project implements an interactive text generation tool using OpenAI's GPT-2 model. It uses the Hugging Face Transformers library to load pre-trained GPT-2 models and generate human-like text continuations.

## 🔍 Overview

- **Interactive Text Generation:** Enter any prompt and receive a coherent text continuation.
- **Model Size Selection:** Choose from GPT-2 small, medium, large, or xl.
- **Temperature Control:** Tune creativity/randomness in output.
- **Customizable Output:** Adjust text length and repetition constraints.

## ✨ Features

- 💬 Real-time prompt interaction
- 🎛️ Adjustable temperature (0.1 - 1.0)
- 🧠 Supports multiple model sizes
- ⚙️ Configurable output parameters

## 📦 Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/Jagdish918/GENERATIVE-TEXT-MODEL/tree/main
   cd gpt2-text-generator
![image](https://github.com/user-attachments/assets/a19407b4-e46f-4548-ad9c-0ad600a353eb)
